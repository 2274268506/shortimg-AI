# 批量上传超时问题修复记录

## 问题描述

### 现象
- **错误类型**: `AxiosError: timeout of 30000ms exceeded`
- **错误码**: `ERR_NETWORK` / `ERR_CONNECTION_ABORTED`
- **发生场景**: 批量上传多个图片文件时
- **单文件上传**: 正常工作
- **批量上传**: 超时失败

### 错误日志
```
POST http://localhost:8080/api/images/batch-upload net::ERR_CONNECTION_ABORTED
```

后端日志显示：
```
2025-12-07 19:25:32  Client error  {"status": 401, "method": "POST", "path": "/api/images/batch-upload"}
```

## 根本原因分析

### 1. 前端超时设置
- **Axios 默认超时**: 30 秒（30000ms）
- **问题**: 批量上传多个文件可能需要更长时间
  - 文件上传时间 = 单个文件大小 * 文件数量 / 网络速度
  - 例如：10个 5MB 的图片 ≈ 50MB，在慢速网络下可能超过30秒

### 2. 后端超时配置
**初始状态**：
- 后端使用 Gin 默认 HTTP 服务器配置
- **无显式超时设置**，可能导致：
  - ReadTimeout: 默认值（可能较短）
  - WriteTimeout: 默认值（可能较短）
  - 大文件上传时服务器端提前断开连接

## 解决方案

### 1. 后端超时配置（已实施）✅

**修改文件**: `backend/main.go`

**更新内容**:
```go
// 创建带超时配置的 HTTP 服务器
srv := &http.Server{
    Addr:           fmt.Sprintf(":%d", cfg.Server.Port),
    Handler:        router,
    ReadTimeout:    5 * time.Minute,  // 读取请求超时：5分钟
    WriteTimeout:   5 * time.Minute,  // 写入响应超时：5分钟
    IdleTimeout:    2 * time.Minute,  // 空闲连接超时：2分钟
    MaxHeaderBytes: 1 << 20,          // 最大请求头：1MB
}
```

**配置说明**:
- **ReadTimeout (5分钟)**:
  - 从连接建立到请求体完全读取的最大时间
  - 适用于大文件上传场景
  - 计算公式：文件大小(MB) / 预期最低上传速度(MB/s)

- **WriteTimeout (5分钟)**:
  - 从请求头读取完成到响应写入完成的最大时间
  - 包含处理时间 + 响应发送时间

- **IdleTimeout (2分钟)**:
  - Keep-Alive 连接的空闲超时时间
  - 防止长时间占用连接资源

**部署步骤**:
```powershell
# 重新构建并启动后端容器
docker-compose -f docker-compose.mysql-test.yml up -d --build backend
```

### 2. 前端超时配置（待实施）⚠️

**需要修改**: `frontend/src/utils/request.ts`

**建议更新**:
```typescript
// 当前配置
const request = axios.create({
  baseURL: import.meta.env.VITE_API_BASE_URL || 'http://localhost:8080',
  timeout: 30000, // ❌ 30秒对批量上传可能不够
  headers: {
    'Content-Type': 'application/json',
  },
});

// 推荐配置
const request = axios.create({
  baseURL: import.meta.env.VITE_API_BASE_URL || 'http://localhost:8080',
  timeout: 300000, // ✅ 5分钟 (300000ms)，与后端一致
  headers: {
    'Content-Type': 'application/json',
  },
});
```

**或者针对批量上传使用单独配置**:
```typescript
// 在批量上传函数中
export const batchUploadImages = (formData: FormData) => {
  return request.post('/api/images/batch-upload', formData, {
    headers: {
      'Content-Type': 'multipart/form-data',
    },
    timeout: 300000, // 批量上传使用5分钟超时
  });
};
```

## 测试验证

### 测试用例

#### 1. 单文件上传测试
- **文件大小**: 1-10 MB
- **预期结果**: 成功上传，耗时 < 30秒
- **状态**: ✅ 已通过

#### 2. 批量上传测试（小文件）
- **文件数量**: 5-10个
- **单文件大小**: 1-2 MB
- **总大小**: 5-20 MB
- **预期结果**: 成功上传，耗时 < 1分钟
- **状态**: ⏳ 待测试

#### 3. 批量上传测试（大文件）
- **文件数量**: 5-10个
- **单文件大小**: 5-10 MB
- **总大小**: 25-100 MB
- **预期结果**: 成功上传，耗时 < 3分钟
- **状态**: ⏳ 待测试

### 测试步骤

1. **更新前端超时配置** (如上述方案2)

2. **重启前端开发服务器**:
   ```powershell
   cd frontend
   npm run dev
   ```

3. **执行批量上传测试**:
   - 准备 5-10 个测试图片（不同大小）
   - 在前端界面选择批量上传
   - 观察浏览器 Network 面板：
     - 请求状态应为 `200 OK`
     - 请求时长应在超时限制内
     - 无 `ERR_CONNECTION_ABORTED` 错误

4. **检查后端日志**:
   ```powershell
   docker logs shortimg-backend-test --tail 50
   ```
   - 应显示 `200 POST /api/images/batch-upload`
   - 无 401 或其他错误日志

## 性能优化建议

### 1. 断点续传支持
对于超大文件，建议实现：
- 文件分块上传（Chunked Upload）
- 断点续传功能
- 上传进度显示

### 2. 并发控制
批量上传时：
```typescript
// 使用 Promise 队列控制并发数
const concurrencyLimit = 3; // 最多同时上传3个文件
```

### 3. 压缩优化
- 客户端图片压缩（减少上传大小）
- 使用 WebP 格式（更高压缩比）

### 4. 网络监测
```typescript
// 动态调整超时时间
const getUploadTimeout = (fileSize: number) => {
  const minSpeed = 100 * 1024; // 100KB/s 最低速度
  const baseTimeout = 30000;   // 基础30秒
  const calculatedTimeout = (fileSize / minSpeed) * 1000;
  return Math.max(baseTimeout, calculatedTimeout);
};
```

## Docker Compose 健康检查修复

### 问题
健康检查使用 `wget --spider`（HEAD 请求），但后端路由只配置了 GET 方法：
```
2025-12-07 19:27:26  Client error  {"status": 404, "method": "HEAD", "path": "/health"}
```

### 解决方案
**修改**: `docker-compose.mysql-test.yml`

**更新前**:
```yaml
healthcheck:
  test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/health" ]
```

**更新后**:
```yaml
healthcheck:
  test: [ "CMD", "wget", "--quiet", "--tries=1", "-O", "/dev/null", "http://localhost:8080/health" ]
```

**差异说明**:
- `--spider`: 发送 HEAD 请求（不下载内容）
- `-O /dev/null`: 发送 GET 请求并丢弃响应内容
- 与后端 `r.GET("/health", ...)` 路由配置一致

## 监控指标

### 关键指标
1. **上传成功率**:
   - 目标: > 99%
   - 监控方式: 统计 2xx vs 4xx/5xx 响应

2. **平均上传时间**:
   - 单文件: < 10秒
   - 批量上传(5个): < 30秒
   - 批量上传(10个): < 60秒

3. **超时错误率**:
   - 目标: < 0.1%
   - 监控: `ERR_CONNECTION_ABORTED` 错误数

### Prometheus 监控查询
```promql
# 上传请求成功率
rate(http_requests_total{path="/api/images/batch-upload", status=~"2.."}[5m])
/
rate(http_requests_total{path="/api/images/batch-upload"}[5m])

# 平均响应时间
rate(http_request_duration_seconds_sum{path="/api/images/batch-upload"}[5m])
/
rate(http_request_duration_seconds_count{path="/api/images/batch-upload"}[5m])
```

## 回滚计划

如遇到问题，可以回滚超时配置：

### 后端回滚
```go
// 恢复为 Gin 默认配置
router.Run(fmt.Sprintf(":%d", cfg.Server.Port))
```

### 前端回滚
```typescript
// 恢复默认30秒超时
timeout: 30000
```

### Docker 回滚
```powershell
# 恢复之前的镜像版本
docker-compose -f docker-compose.mysql-test.yml down
git checkout HEAD~1 docker-compose.mysql-test.yml backend/main.go
docker-compose -f docker-compose.mysql-test.yml up -d
```

## 相关问题

### 缓存导致上传后图片不可见 ⚠️

**问题描述**：
- 批量上传成功后，刷新页面无法立即看到新上传的图片
- 需要等待 5 分钟（缓存过期时间）才能看到

**根本原因**：
图片列表API (`GET /api/images`) 使用了 5 分钟的缓存：
```go
images.GET("", middleware.CacheMiddleware(5*time.Minute), controllers.GetImages)
```

上传成功后，前端立即请求图片列表，但返回的是缓存中的旧数据（不包含新上传的图片）。

**解决方案** ✅：

1. **在 `image_controller.go` 中添加缓存清除函数**：
```go
// clearImageListCache 清除图片列表相关的缓存
func clearImageListCache(albumID uint64) {
    // 清除该相册的所有图片列表缓存
    pattern := fmt.Sprintf("cache:GET:/api/images?albumId=%d*", albumID)
    cache.DeletePattern(pattern)

    // 同时清除该相册的缓存
    albumCacheKey := fmt.Sprintf("cache:GET:/api/albums/%d*", albumID)
    cache.DeletePattern(albumCacheKey)
}
```

2. **在关键操作后调用清除缓存**：
   - ✅ 单张图片上传后 (`UploadImage`)
   - ✅ 批量上传后 (`BatchUpload`)
   - ✅ 删除图片后 (`DeleteImage`)

**修改文件**：
- `backend/controllers/image_controller.go`
  - 添加 `imagebed/cache` 导入
  - 添加 `clearImageListCache()` 函数
  - 在 `UploadImage()` 中调用缓存清除
  - 在 `BatchUpload()` 中调用缓存清除
  - 在 `DeleteImage()` 中调用缓存清除

**技术细节**：
- 使用 Redis 的 `SCAN` 命令进行模式匹配删除
- 删除所有包含该相册ID的图片列表缓存键
- 同时清除相册详情缓存（因为包含图片数量）

**效果**：
- ✅ 上传后立即可见（无需等待5分钟）
- ✅ 删除后立即生效
- ✅ 不影响其他相册的缓存
- ✅ 保持缓存机制的性能优势

**测试验证**：
```powershell
# 1. 批量上传图片
# 2. 立即刷新页面
# 3. 应该立即看到新上传的图片（无需等待）
```

---

## 相关文档

- [HTTP 超时配置最佳实践](https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/)
- [Axios 超时处理](https://axios-http.com/docs/req_config)
- [Gin 框架性能优化](https://gin-gonic.com/docs/examples/)
- [Docker 健康检查文档](https://docs.docker.com/engine/reference/builder/#healthcheck)

## 变更历史

| 日期 | 版本 | 变更内容 | 作者 |
|------|------|----------|------|
| 2025-12-07 | 1.0 | 初始版本：后端超时配置修复 + Docker 健康检查修复 | GitHub Copilot |

## 下一步行动

1. ✅ **后端超时配置** - 已完成
2. ⚠️ **前端超时配置** - 待实施
3. ⏳ **批量上传测试** - 待验证
4. 📋 **性能监控** - 待部署
5. 🔍 **用户反馈收集** - 待开始

---

**注意**: 请在更新前端超时配置后，进行充分的批量上传测试，确保各种场景下都能正常工作。
